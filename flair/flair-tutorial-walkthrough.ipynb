{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Flair Walkthrough_\n",
    "\n",
    "This notebook will walkthrough how to use [flair](https://github.com/flairNLP/flair), a simple framework built directly on PyTorch, that makes it easy to train your own NLP models and experiment with new approaches using Flair embeddings and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [_Tutorial 1: NLP Base Types_](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_1_BASICS.md)\n",
    "\n",
    "- two types of objects central to `flair`\n",
    "    - `Sentence` object: holds a textual sentence (essentially a list of `Token`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "# the sentence object holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print out tells us sentence consists of 5 tokens\n",
    "- you can access tokens within sentence via their token id or their index\n",
    "- the print out will include the ID and lexical value of the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 green\n",
      "Token: 4 green\n"
     ]
    }
   ],
   "source": [
    "# print using the token id\n",
    "print(sentence.get_token(4))\n",
    "# print using the index itself\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "Token: 2 grass\n",
      "Token: 3 is\n",
      "Token: 4 green\n",
      "Token: 5 .\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Tokenization_\n",
    "\n",
    "- in cases where text is not already tokenized, can use `use_tokenizer` flag when instantiating `Sentence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "# make sentence object by passing an untokenized string and use_tokenizer flag\n",
    "sentence = Sentence('The grass is green.', use_tokenizer=True)\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Adding Custom Tokenizers_\n",
    "\n",
    "- can also pass custom tokenizers to `use_tokenizer` flag\n",
    "    - pass a tokenization method instead of a `True` boolean\n",
    "    - check the code of [`flair.data.space_tokenizer`](https://github.com/flairNLP/flair/blob/master/flair/data.py) to get idea of how to implement a wrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "from flair.data import segtok_tokenizer\n",
    "\n",
    "# make a sentence object by passing in untokenized string and custom tokenizer\n",
    "sentence = Sentence('The grass is green.', use_tokenizer=segtok_tokenizer)\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Adding Tags to Tokens_\n",
    "\n",
    "- `Token` has fields for linguistic annotation, such as:\n",
    "    - lemmas\n",
    "    - part-of-speech tags\n",
    "    - named entity tags\n",
    "- can add a tag by specifying tag type & value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grass is green <color> .\n"
     ]
    }
   ],
   "source": [
    "# add NER tag of type color to the word green --> tagged word as an entity of type color\n",
    "sentence[3].add_tag('ner', 'color')\n",
    "\n",
    "# print the sentence with all tags of this type\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Token: 4 green\" is tagged as \"color\" with confidence score \"1.0\"\n"
     ]
    }
   ],
   "source": [
    "# each tag is of class Label, which next to the value has a score indicating confidence\n",
    "# get token 3 in sentence\n",
    "token = sentence[3]\n",
    "\n",
    "# get the ner tag of the token\n",
    "tag = token.get_tag('ner')\n",
    "\n",
    "# print token\n",
    "print(f'\"{token}\" is tagged as \"{tag.value}\" with confidence score \"{tag.score}\"')\n",
    "# our color tag will have a score of 1.0 because we manually added it\n",
    "# if tag is predicted by sequence labeler, the score value will\n",
    "# indicate classifier confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Adding Labels to Sentences_\n",
    "\n",
    "- `Sentence` can have one or more labels that can be used in text classification tasks (for example)\n",
    "- example below will add label `sports` to the sentence\n",
    "    - labeling it as belonging to the `sports` category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports (1.0)\n",
      "world cup (1.0)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('France is the current World Cup winner.')\n",
    "\n",
    "# add a label to a sentence\n",
    "sentence.add_label('sports')\n",
    "\n",
    "# a sentence can also belong to multiple classes\n",
    "sentence.add_labels(['sports', 'world cup'])\n",
    "\n",
    "# you can also set the labels while initializing the sentence\n",
    "sentence = Sentence('France is the current World Cup winner.', labels=['sports', 'world cup'])\n",
    "\n",
    "# you can print a sentence's labels like this\n",
    "for label in sentence.labels:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [_Tutorial 2: Tagging your Text_](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md)\n",
    "\n",
    "- below will show how to use `flair`'s pretrained models to tag your text\n",
    "\n",
    "### _Tagging with Pre-trained Sequence Tagging Models_\n",
    "\n",
    "- we'll use pre-trained model for named entity recognition (NER)\n",
    "    - model was trained over the English [CoNLL-03](https://dl.acm.org/doi/10.3115/1119176.1119195) task \n",
    "        - can recognize 4 different entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-20 00:06:12,826 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
      "George <B-PER> Washington <E-PER> went to Washington <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "sentence = Sentence('George Washington went to Washington.', use_tokenizer=True)\n",
    "\n",
    "# use predict() method of the tagger on the sentence\n",
    "# this will add predicted tags to the tokens in the sentence\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print the sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-span [1,2]: \"George Washington\"\n",
      "LOC-span [5]: \"Washington\"\n"
     ]
    }
   ],
   "source": [
    "# we can directly get such spans in a tagged sentence like this\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- above indicats that:\n",
    "    - \"George Washington\" is a person (PER)\n",
    "    - \"Washington\" is a location (LOC)\n",
    "- we can get additional information by calling the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'George Washington went to Washington.', 'labels': [], 'entities': [{'text': 'George Washington', 'start_pos': 0, 'end_pos': 17, 'type': 'PER', 'confidence': 0.9967881441116333}, {'text': 'Washington', 'start_pos': 26, 'end_pos': 36, 'type': 'LOC', 'confidence': 0.9993711113929749}]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _List of Pre-Trained Sequence Tagger Models_\n",
    "\n",
    "- you can choose which pre-trained model you load\n",
    "    - can be done by passing appropriate string to the `load()` method of `SequenceTagger` class\n",
    "- for more information on ID's (i.e. the strings to use to load models), check out the list [here](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md#list-of-pre-trained-sequence-tagger-models)\n",
    "\n",
    "### _Tagging a German sentence_\n",
    "\n",
    "- there are pre-trained models for languages other than English\n",
    "- current languages that are supported:\n",
    "    - German, French and Dutch\n",
    "- the cell below is commented out because the model would've taken ~30min to load..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load German model\n",
    "#tagger = SequenceTagger.load('de-ner')\n",
    "\n",
    "# make a German sentence\n",
    "#sentence = Sentence('George Washington ging nach Washington.', use_tokenizer=True)\n",
    "\n",
    "# predict NER tags\n",
    "#tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "#print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Experimental: Semantic Frame Detection_\n",
    "\n",
    "- has pre-trained model that detect semantic frames in text\n",
    "    - trained using [Propbank 3.0 frames](https://propbank.github.io/)\n",
    "- provides word sense disambiguation for frame evoking words\n",
    "- commented out due to size of model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#tagger = SequenceTagger.load('frame')\n",
    "\n",
    "# make English sentence\n",
    "#sentence1 = Sentence('George returned to Berlin to return his hat.', use_tokenizer=True)\n",
    "#sentence2 = Sentence('He had a look at different hats.', use_tokenizer=True)\n",
    "\n",
    "# predict NER tags\n",
    "#tagger.predict(sentence1)\n",
    "#tagger.predict(sentence2)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "#print(sentence1.to_tagged_string())\n",
    "#print(sentence2.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is what the output for the above cell would look like\n",
    "\n",
    "```\n",
    "George returned <return.01> to Berlin to return <return.02> his hat .\n",
    "\n",
    "He had <have.LV> a look <look.01> at different hats .\n",
    "```\n",
    "\n",
    "- frame detector makes distinction in sentence 1 between different meanings of the word `return`\n",
    "    - `return.01` means returning to a location\n",
    "    - `return.02` means giving something back\n",
    "- in sentence two, frame detector finds light verb construction\n",
    "    - `have` is the light verb\n",
    "    - `look` is a frame evoking word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Tagging a List of Sentences_\n",
    "\n",
    "- may want to tag an entire text corpus\n",
    "    - need to split the corpus into sentences \n",
    "    - then pass a list of `Sentence` objects to `.predict()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-20 00:37:11,465 loading file /root/.flair/models/en-ner-conll03-v0.4.pt\n",
      "This is a sentence .\n",
      "This is another sentence .\n",
      "I love Berlin <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "# text of many sentences\n",
    "text = 'This is a sentence. This is another sentence. I love Berlin.'\n",
    "\n",
    "# use library to split into sentences\n",
    "from segtok.segmenter import split_single\n",
    "\n",
    "sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(text)]\n",
    "\n",
    "# predict tags for list of sentences\n",
    "tagger = SequenceTagger.load('ner')\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# iterate through the sentences and print predicted labels\n",
    "for sent in sentences:\n",
    "    print(sent.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `mini_batch_size` parameter of `predict()` method\n",
    "    - can set size of mini-batches passed to the tagger\n",
    "- may have to play around with this paramater to optimize speed\n",
    "\n",
    "### _Tagging with Pre-Trained Text Classification Models_\n",
    "\n",
    "- can use pre-trained model for detecting positive or negative comments\n",
    "    - model was trained over IMDB dataset\n",
    "    - can recognize positive and negative sentiment in English text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flair.models import TextClassifier\n",
    "\n",
    "#classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "#sentence = Sentence('This film hurts. It is so bad that I am confused.', use_tokenizer=True)\n",
    "\n",
    "# predict NEW tags\n",
    "#classifier.predict(setence)\n",
    "\n",
    "# print sentence with predicted labels\n",
    "#print(sentence.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- above cell should print the following\n",
    "```\n",
    "[NEGATIVE (0.9598667025566101)]\n",
    "```\n",
    "- contains the sentiment and the confidence\n",
    "- here is a [link](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md#list-of-pre-trained-text-classification-models) to the list of pre-trained text classification models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
