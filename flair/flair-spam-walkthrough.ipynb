{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Word Embeddings & Text Classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d uciml/sms-spam-collection-dataset -p ~/.kaggle\n",
    "#!unzip ~/.kaggle/sms-spam-collection-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Get Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapath():\n",
    "    # gets path to resources folder\n",
    "    return Path().cwd().parent / 'resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = datapath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(datapath):\n",
    "    df = pd.read_csv(datapath/'spam.csv', encoding='ISO-8859-1')\n",
    "    df = df[['v1','v2']]\n",
    "    df.columns = ['labels','text']\n",
    "    df.labels = df.labels.replace('ham',0)\n",
    "    df.labels = df.labels.replace('spam',1)\n",
    "    df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[Û_] anyway, many good evenings to u! s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>My sort code is  and acc no is . The bank is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry i din lock my keypad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok i thk i got it. Then u wan me 2 come now or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Oi when you gonna ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Will be office around 4 pm. Now i am going hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Have you heard about that job? I'm going to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh my God. I'm almost home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0                           Convey my regards to him\n",
       "1       0           [Û_] anyway, many good evenings to u! s\n",
       "2       0  My sort code is  and acc no is . The bank is n...\n",
       "3       0                        Sorry i din lock my keypad.\n",
       "4       1  Hi babe its Chloe, how r u? I was smashed on s...\n",
       "5       0  Ok i thk i got it. Then u wan me 2 come now or...\n",
       "6       0                             Oi when you gonna ring\n",
       "7       0  Will be office around 4 pm. Now i am going hos...\n",
       "8       0  Have you heard about that job? I'm going to th...\n",
       "9       0                         Oh my God. I'm almost home"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_text(datapath)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spams:  747\n",
      "number of non-spams:  4825\n",
      "number of documents:  5572\n"
     ]
    }
   ],
   "source": [
    "print('number of spams: ',len(df[df.labels==1]))\n",
    "print('number of non-spams: ',len(df[df.labels==0]))\n",
    "print('number of documents: ', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Text Normalization and Tokenization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_special_tokens(text):\n",
    "    # note I stole many of these regexes regularly from S.O.\n",
    "    # convert simple URLs to xxurl token (e.g. www.google.com, http:google.com -> xxurl)\n",
    "    text = re.sub(r' www.', ' http://www.', text)\n",
    "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' xxurl ', text)\n",
    "    # convert (British) phone numbers to xxphone token (e.g. 09058097218 -> xxphone)\n",
    "    pat = r'\\d{3}[-\\.\\s]??\\d{4}[-\\.\\s]??\\d{4}|\\d{5}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{3}|(?:\\d{4}\\)?[\\s-]?\\d{3}[\\s-]?\\d{4})'\n",
    "    text = re.sub(pat, ' xxphone ', text)\n",
    "    # replace monetary values with xxmon token\n",
    "    text = text.replace('£','$ ')\n",
    "    text = re.sub(r'(\\d+)[ ]{0,1}p', '$ 0.\\1', text)\n",
    "    text = re.sub(r'\\$[ ]*(\\d+[,\\.])*\\d+', ' xxmon ', text)\n",
    "    # put xxup token before words in all caps (easy way to recognize info from capitalizing a word)\n",
    "    text = re.sub(r'(\\b[A-Z][A-Z0-9]*\\b)', r' xxup \\1 ', text)\n",
    "    # put xxcap token before words with capitalized first letter (easy way to recognize first word in a sentence)\n",
    "    text = re.sub(r'(\\b[A-Z][a-z0-9]+\\b)', r' xxcap \\1 ', text)\n",
    "    # convert some common text \"emojis\" to xxemoji: ;), :), :(, :-(, etc\n",
    "    text = re.sub(r'[:;][ ]*[-]*[ ]*[()]', ' xxemoji ', text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    # converts common patterns into special tokens\n",
    "    text = sub_special_tokens(text)\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # strip out any lingering html tags\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    # convert all common abrevs to regular word\n",
    "    text = text.replace('&',' and ')\n",
    "    text = re.sub(r'\\bu\\b', ' you ', text)\n",
    "    text = re.sub(r'\\bur\\b', ' your ', text)\n",
    "    text = re.sub(r'\\b2\\b', ' to ', text)\n",
    "    text = re.sub(r'\\b4\\b', ' for ', text)\n",
    "    # put spaces between punctuation (eg: 9.Blah -> 9 . Blah)\n",
    "    puncts = r'[' + re.escape(string.punctuation) + r']'\n",
    "    text = re.sub('(?<! )(?=' + puncts + ')|(?<=' + puncts + ')(?! )', r' ', text)\n",
    "    # strip non-ascii characters (easy way to denoise text a bit)\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    # remove all punctuation except ?\n",
    "    text = re.sub(r\"[^\\w\\s?]\",' xxpunct ',text)\n",
    "    # convert all other numbers to xxnum token (e.g. 123, 1.2.3, 1-2-3 -> xxnum)\n",
    "    text = re.sub(r'\\b([.-]*[0-9]+[.-]*)+\\b', ' xxnum ', text)\n",
    "    # remove nltk's common set of stop words (common for classical NLP analysis)\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    # stem words using nltk snowball stemmer, e.g. converts {run, running, runs} all to \"run\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_text = ''\n",
    "    for word in text.split():\n",
    "            stemmed_text = stemmed_text + stemmer.stem(word) + ' '\n",
    "    text = stemmed_text\n",
    "    # sub the occurance of 2 or more spaces with a single space\n",
    "    text = re.sub(r'[ ]{2,}',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Convey my regards to him</td>\n",
       "      <td>xxcap convey regard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[Û_] anyway, many good evenings to u! s</td>\n",
       "      <td>xxpunct _ xxpunct anyway xxpunct mani good eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>My sort code is  and acc no is . The bank is n...</td>\n",
       "      <td>xxcap sort code acc xxpunct xxcap bank natwest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry i din lock my keypad.</td>\n",
       "      <td>xxcap sorri din lock keypad xxpunct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>xxcap hi babe xxcap chloe xxpunct r ? xxup sma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok i thk i got it. Then u wan me 2 come now or...</td>\n",
       "      <td>xxcap ok thk got xxpunct xxcap wan come wat ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Oi when you gonna ring</td>\n",
       "      <td>xxcap oi gonna ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Will be office around 4 pm. Now i am going hos...</td>\n",
       "      <td>xxcap offic around xxmon xxpunct xxpunct xxpun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Have you heard about that job? I'm going to th...</td>\n",
       "      <td>xxcap heard job ? xxup xxpunct go wildlif talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh my God. I'm almost home</td>\n",
       "      <td>xxcap oh xxcap god xxpunct xxup xxpunct almost...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text  \\\n",
       "0       0                           Convey my regards to him   \n",
       "1       0           [Û_] anyway, many good evenings to u! s   \n",
       "2       0  My sort code is  and acc no is . The bank is n...   \n",
       "3       0                        Sorry i din lock my keypad.   \n",
       "4       1  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "5       0  Ok i thk i got it. Then u wan me 2 come now or...   \n",
       "6       0                             Oi when you gonna ring   \n",
       "7       0  Will be office around 4 pm. Now i am going hos...   \n",
       "8       0  Have you heard about that job? I'm going to th...   \n",
       "9       0                         Oh my God. I'm almost home   \n",
       "\n",
       "                                      text_processed  \n",
       "0                               xxcap convey regard   \n",
       "1  xxpunct _ xxpunct anyway xxpunct mani good eve...  \n",
       "2  xxcap sort code acc xxpunct xxcap bank natwest...  \n",
       "3               xxcap sorri din lock keypad xxpunct   \n",
       "4  xxcap hi babe xxcap chloe xxpunct r ? xxup sma...  \n",
       "5     xxcap ok thk got xxpunct xxcap wan come wat ?   \n",
       "6                               xxcap oi gonna ring   \n",
       "7  xxcap offic around xxmon xxpunct xxpunct xxpun...  \n",
       "8  xxcap heard job ? xxup xxpunct go wildlif talk...  \n",
       "9  xxcap oh xxcap god xxpunct xxup xxpunct almost...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_processed'] = df['text'].apply(normalize_text)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    tokens = ' '.join(token.text for token in doc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_processed'] = df['text_processed'].apply(lambda x: tokenize(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(datapath/'spam_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spampath():\n",
    "    # gets path to resources folder\n",
    "    return Path().cwd().parent / 'spam_data'\n",
    "\n",
    "spampath = spampath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(df.sample(frac=1, random_state=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3343 entries, 1078 to 425\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   labels          3343 non-null   int64 \n",
      " 1   text            3343 non-null   object\n",
      " 2   text_processed  3343 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(spampath/'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1114 entries, 697 to 371\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   labels          1114 non-null   int64 \n",
      " 1   text            1114 non-null   object\n",
      " 2   text_processed  1114 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "validate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.to_csv(spampath/'dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1115 entries, 3482 to 5157\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   labels          1115 non-null   int64 \n",
      " 1   text            1115 non-null   object\n",
      " 2   text_processed  1115 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(spampath/'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Embeddings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, DocumentRNNEmbeddings, Sentence\n",
    "\n",
    "# initialize the word embeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "# initialize the document embeddings, mode = mean\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding,\n",
    "                                              flair_embedding_backward,\n",
    "                                              flair_embedding_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:33:00,079 Reading data from /notebooks/learning/spam_data\n",
      "2020-05-21 20:33:00,080 Train: /notebooks/learning/spam_data/train.csv\n",
      "2020-05-21 20:33:00,081 Dev: /notebooks/learning/spam_data/dev.csv\n",
      "2020-05-21 20:33:00,081 Test: /notebooks/learning/spam_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "data_folder = spampath\n",
    "\n",
    "column_name_map = {2: 'text', 0: 'label_topic'}\n",
    "\n",
    "corpus = CSVClassificationCorpus(\n",
    "    data_folder,\n",
    "    column_name_map,\n",
    "    skip_header=True,\n",
    "    delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:33:01,423 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3343/3343 [00:00<00:00, 3625.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:33:02,631 [b'0', b'1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('glove')]\n",
    "\n",
    "# init document embedding \n",
    "document_embeddings = DocumentRNNEmbeddings(\n",
    "    word_embeddings,\n",
    "    hidden_size=512,\n",
    "    reproject_words=True,\n",
    "    reproject_words_dimension=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:36:14,533 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,534 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-05-21 20:36:14,535 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,536 Corpus: \"Corpus: 3343 train + 1114 dev + 1115 test sentences\"\n",
      "2020-05-21 20:36:14,536 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,537 Parameters:\n",
      "2020-05-21 20:36:14,538  - learning_rate: \"0.1\"\n",
      "2020-05-21 20:36:14,538  - mini_batch_size: \"32\"\n",
      "2020-05-21 20:36:14,539  - patience: \"3\"\n",
      "2020-05-21 20:36:14,539  - anneal_factor: \"0.5\"\n",
      "2020-05-21 20:36:14,540  - max_epochs: \"10\"\n",
      "2020-05-21 20:36:14,540  - shuffle: \"True\"\n",
      "2020-05-21 20:36:14,541  - train_with_dev: \"False\"\n",
      "2020-05-21 20:36:14,542  - batch_growth_annealing: \"False\"\n",
      "2020-05-21 20:36:14,542 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,543 Model training base path: \"/notebooks/learning/spam_data\"\n",
      "2020-05-21 20:36:14,543 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,544 Device: cuda:0\n",
      "2020-05-21 20:36:14,545 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:14,545 Embeddings storage mode: cpu\n",
      "2020-05-21 20:36:14,549 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:15,557 epoch 1 - iter 10/105 - loss 0.42335005 - samples/sec: 448.26\n",
      "2020-05-21 20:36:16,254 epoch 1 - iter 20/105 - loss 0.40100195 - samples/sec: 478.95\n",
      "2020-05-21 20:36:16,902 epoch 1 - iter 30/105 - loss 0.38860851 - samples/sec: 525.58\n",
      "2020-05-21 20:36:17,542 epoch 1 - iter 40/105 - loss 0.38773113 - samples/sec: 535.55\n",
      "2020-05-21 20:36:18,155 epoch 1 - iter 50/105 - loss 0.37980908 - samples/sec: 545.42\n",
      "2020-05-21 20:36:18,765 epoch 1 - iter 60/105 - loss 0.36565106 - samples/sec: 563.13\n",
      "2020-05-21 20:36:19,418 epoch 1 - iter 70/105 - loss 0.35421390 - samples/sec: 527.41\n",
      "2020-05-21 20:36:20,104 epoch 1 - iter 80/105 - loss 0.34482693 - samples/sec: 495.31\n",
      "2020-05-21 20:36:20,749 epoch 1 - iter 90/105 - loss 0.33751691 - samples/sec: 514.26\n",
      "2020-05-21 20:36:21,345 epoch 1 - iter 100/105 - loss 0.32906972 - samples/sec: 573.04\n",
      "2020-05-21 20:36:21,672 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:21,673 EPOCH 1 done: loss 0.3272 - lr 0.1000\n",
      "2020-05-21 20:36:23,715 DEV : loss 0.3075461983680725 - score 0.8716\n",
      "2020-05-21 20:36:24,254 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:36:27,435 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:28,416 epoch 2 - iter 10/105 - loss 0.27362459 - samples/sec: 473.80\n",
      "2020-05-21 20:36:30,180 epoch 2 - iter 20/105 - loss 0.26663996 - samples/sec: 617.87\n",
      "2020-05-21 20:36:30,726 epoch 2 - iter 30/105 - loss 0.27462160 - samples/sec: 616.00\n",
      "2020-05-21 20:36:31,211 epoch 2 - iter 40/105 - loss 0.26548265 - samples/sec: 690.82\n",
      "2020-05-21 20:36:31,705 epoch 2 - iter 50/105 - loss 0.26159456 - samples/sec: 698.76\n",
      "2020-05-21 20:36:32,199 epoch 2 - iter 60/105 - loss 0.26583641 - samples/sec: 696.67\n",
      "2020-05-21 20:36:32,717 epoch 2 - iter 70/105 - loss 0.26161193 - samples/sec: 648.24\n",
      "2020-05-21 20:36:33,250 epoch 2 - iter 80/105 - loss 0.26723381 - samples/sec: 643.57\n",
      "2020-05-21 20:36:33,775 epoch 2 - iter 90/105 - loss 0.26482380 - samples/sec: 652.68\n",
      "2020-05-21 20:36:34,255 epoch 2 - iter 100/105 - loss 0.26503046 - samples/sec: 710.83\n",
      "2020-05-21 20:36:34,584 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:34,585 EPOCH 2 done: loss 0.2628 - lr 0.1000\n",
      "2020-05-21 20:36:36,392 DEV : loss 0.2575683295726776 - score 0.8914\n",
      "2020-05-21 20:36:36,952 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:36:40,522 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:41,362 epoch 3 - iter 10/105 - loss 0.29216389 - samples/sec: 625.72\n",
      "2020-05-21 20:36:41,958 epoch 3 - iter 20/105 - loss 0.27958647 - samples/sec: 568.17\n",
      "2020-05-21 20:36:42,583 epoch 3 - iter 30/105 - loss 0.26982426 - samples/sec: 542.12\n",
      "2020-05-21 20:36:43,214 epoch 3 - iter 40/105 - loss 0.24604789 - samples/sec: 538.63\n",
      "2020-05-21 20:36:43,887 epoch 3 - iter 50/105 - loss 0.24659763 - samples/sec: 502.79\n",
      "2020-05-21 20:36:44,482 epoch 3 - iter 60/105 - loss 0.23864326 - samples/sec: 554.23\n",
      "2020-05-21 20:36:45,104 epoch 3 - iter 70/105 - loss 0.23402606 - samples/sec: 547.83\n",
      "2020-05-21 20:36:47,096 epoch 3 - iter 80/105 - loss 0.23369508 - samples/sec: 556.60\n",
      "2020-05-21 20:36:47,636 epoch 3 - iter 90/105 - loss 0.23561053 - samples/sec: 632.20\n",
      "2020-05-21 20:36:48,129 epoch 3 - iter 100/105 - loss 0.22664421 - samples/sec: 672.04\n",
      "2020-05-21 20:36:48,496 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:48,498 EPOCH 3 done: loss 0.2204 - lr 0.1000\n",
      "2020-05-21 20:36:50,454 DEV : loss 0.17674866318702698 - score 0.9452\n",
      "2020-05-21 20:36:50,993 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:36:54,493 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:36:55,434 epoch 4 - iter 10/105 - loss 0.15579822 - samples/sec: 561.79\n",
      "2020-05-21 20:36:55,983 epoch 4 - iter 20/105 - loss 0.17279472 - samples/sec: 605.54\n",
      "2020-05-21 20:36:56,486 epoch 4 - iter 30/105 - loss 0.17832241 - samples/sec: 691.00\n",
      "2020-05-21 20:36:57,024 epoch 4 - iter 40/105 - loss 0.19755473 - samples/sec: 642.39\n",
      "2020-05-21 20:36:57,608 epoch 4 - iter 50/105 - loss 0.18669037 - samples/sec: 573.53\n",
      "2020-05-21 20:36:58,140 epoch 4 - iter 60/105 - loss 0.18666393 - samples/sec: 656.69\n",
      "2020-05-21 20:36:58,677 epoch 4 - iter 70/105 - loss 0.19317082 - samples/sec: 638.80\n",
      "2020-05-21 20:36:59,216 epoch 4 - iter 80/105 - loss 0.19405258 - samples/sec: 632.31\n",
      "2020-05-21 20:36:59,785 epoch 4 - iter 90/105 - loss 0.19483475 - samples/sec: 609.03\n",
      "2020-05-21 20:37:00,356 epoch 4 - iter 100/105 - loss 0.19249507 - samples/sec: 593.69\n",
      "2020-05-21 20:37:00,637 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:00,638 EPOCH 4 done: loss 0.1897 - lr 0.1000\n",
      "2020-05-21 20:37:02,590 DEV : loss 0.1367824226617813 - score 0.9551\n",
      "2020-05-21 20:37:03,123 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:37:06,683 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:09,052 epoch 5 - iter 10/105 - loss 0.13985147 - samples/sec: 158.60\n",
      "2020-05-21 20:37:09,512 epoch 5 - iter 20/105 - loss 0.14784959 - samples/sec: 736.65\n",
      "2020-05-21 20:37:10,006 epoch 5 - iter 30/105 - loss 0.16731818 - samples/sec: 697.94\n",
      "2020-05-21 20:37:10,568 epoch 5 - iter 40/105 - loss 0.15663879 - samples/sec: 616.65\n",
      "2020-05-21 20:37:11,180 epoch 5 - iter 50/105 - loss 0.15840830 - samples/sec: 548.49\n",
      "2020-05-21 20:37:11,724 epoch 5 - iter 60/105 - loss 0.15405373 - samples/sec: 635.43\n",
      "2020-05-21 20:37:12,286 epoch 5 - iter 70/105 - loss 0.15122261 - samples/sec: 613.98\n",
      "2020-05-21 20:37:12,808 epoch 5 - iter 80/105 - loss 0.15832502 - samples/sec: 660.27\n",
      "2020-05-21 20:37:13,345 epoch 5 - iter 90/105 - loss 0.15698120 - samples/sec: 625.05\n",
      "2020-05-21 20:37:13,867 epoch 5 - iter 100/105 - loss 0.15165867 - samples/sec: 660.63\n",
      "2020-05-21 20:37:14,199 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:37:14,200 EPOCH 5 done: loss 0.1506 - lr 0.1000\n",
      "2020-05-21 20:37:16,064 DEV : loss 0.17742173373699188 - score 0.9434\n",
      "2020-05-21 20:37:16,624 BAD EPOCHS (no improvement): 1\n",
      "2020-05-21 20:37:16,625 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:17,532 epoch 6 - iter 10/105 - loss 0.10164637 - samples/sec: 594.21\n",
      "2020-05-21 20:37:18,062 epoch 6 - iter 20/105 - loss 0.12046549 - samples/sec: 659.01\n",
      "2020-05-21 20:37:18,609 epoch 6 - iter 30/105 - loss 0.13060856 - samples/sec: 608.70\n",
      "2020-05-21 20:37:19,207 epoch 6 - iter 40/105 - loss 0.12946705 - samples/sec: 566.98\n",
      "2020-05-21 20:37:19,832 epoch 6 - iter 50/105 - loss 0.14134797 - samples/sec: 545.76\n",
      "2020-05-21 20:37:20,406 epoch 6 - iter 60/105 - loss 0.14396010 - samples/sec: 582.32\n",
      "2020-05-21 20:37:20,900 epoch 6 - iter 70/105 - loss 0.14024993 - samples/sec: 698.36\n",
      "2020-05-21 20:37:22,862 epoch 6 - iter 80/105 - loss 0.13855941 - samples/sec: 635.47\n",
      "2020-05-21 20:37:23,374 epoch 6 - iter 90/105 - loss 0.13884891 - samples/sec: 651.07\n",
      "2020-05-21 20:37:23,862 epoch 6 - iter 100/105 - loss 0.13311367 - samples/sec: 697.64\n",
      "2020-05-21 20:37:24,195 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:24,197 EPOCH 6 done: loss 0.1360 - lr 0.1000\n",
      "2020-05-21 20:37:26,154 DEV : loss 0.1311551183462143 - score 0.9551\n",
      "2020-05-21 20:37:26,715 BAD EPOCHS (no improvement): 2\n",
      "2020-05-21 20:37:30,319 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:31,260 epoch 7 - iter 10/105 - loss 0.12322755 - samples/sec: 546.79\n",
      "2020-05-21 20:37:31,871 epoch 7 - iter 20/105 - loss 0.11516577 - samples/sec: 562.90\n",
      "2020-05-21 20:37:32,426 epoch 7 - iter 30/105 - loss 0.13979327 - samples/sec: 629.83\n",
      "2020-05-21 20:37:32,943 epoch 7 - iter 40/105 - loss 0.14392161 - samples/sec: 653.24\n",
      "2020-05-21 20:37:33,531 epoch 7 - iter 50/105 - loss 0.13747876 - samples/sec: 596.45\n",
      "2020-05-21 20:37:34,063 epoch 7 - iter 60/105 - loss 0.14430470 - samples/sec: 636.55\n",
      "2020-05-21 20:37:34,619 epoch 7 - iter 70/105 - loss 0.13984781 - samples/sec: 624.58\n",
      "2020-05-21 20:37:35,174 epoch 7 - iter 80/105 - loss 0.13600254 - samples/sec: 624.22\n",
      "2020-05-21 20:37:35,690 epoch 7 - iter 90/105 - loss 0.13989397 - samples/sec: 668.70\n",
      "2020-05-21 20:37:36,196 epoch 7 - iter 100/105 - loss 0.14124991 - samples/sec: 679.91\n",
      "2020-05-21 20:37:36,530 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:36,531 EPOCH 7 done: loss 0.1446 - lr 0.1000\n",
      "2020-05-21 20:37:38,362 DEV : loss 0.15181590616703033 - score 0.9417\n",
      "2020-05-21 20:37:40,314 BAD EPOCHS (no improvement): 3\n",
      "2020-05-21 20:37:40,316 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:41,279 epoch 8 - iter 10/105 - loss 0.13007245 - samples/sec: 521.28\n",
      "2020-05-21 20:37:41,820 epoch 8 - iter 20/105 - loss 0.13224829 - samples/sec: 630.05\n",
      "2020-05-21 20:37:42,373 epoch 8 - iter 30/105 - loss 0.15054136 - samples/sec: 626.36\n",
      "2020-05-21 20:37:42,885 epoch 8 - iter 40/105 - loss 0.14199715 - samples/sec: 654.04\n",
      "2020-05-21 20:37:43,481 epoch 8 - iter 50/105 - loss 0.13273443 - samples/sec: 572.38\n",
      "2020-05-21 20:37:43,982 epoch 8 - iter 60/105 - loss 0.14137372 - samples/sec: 684.98\n",
      "2020-05-21 20:37:44,525 epoch 8 - iter 70/105 - loss 0.13735802 - samples/sec: 639.36\n",
      "2020-05-21 20:37:45,062 epoch 8 - iter 80/105 - loss 0.13473836 - samples/sec: 656.74\n",
      "2020-05-21 20:37:45,578 epoch 8 - iter 90/105 - loss 0.13726696 - samples/sec: 663.56\n",
      "2020-05-21 20:37:46,139 epoch 8 - iter 100/105 - loss 0.13672437 - samples/sec: 610.40\n",
      "2020-05-21 20:37:46,486 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:46,487 EPOCH 8 done: loss 0.1347 - lr 0.1000\n",
      "2020-05-21 20:37:48,406 DEV : loss 0.1307533085346222 - score 0.9551\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-21 20:37:48,949 BAD EPOCHS (no improvement): 4\n",
      "2020-05-21 20:37:52,557 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:37:53,477 epoch 9 - iter 10/105 - loss 0.09255617 - samples/sec: 554.97\n",
      "2020-05-21 20:37:54,088 epoch 9 - iter 20/105 - loss 0.10881758 - samples/sec: 561.54\n",
      "2020-05-21 20:37:54,590 epoch 9 - iter 30/105 - loss 0.11761268 - samples/sec: 683.57\n",
      "2020-05-21 20:37:55,181 epoch 9 - iter 40/105 - loss 0.12405235 - samples/sec: 572.10\n",
      "2020-05-21 20:37:55,719 epoch 9 - iter 50/105 - loss 0.12843337 - samples/sec: 628.05\n",
      "2020-05-21 20:37:56,214 epoch 9 - iter 60/105 - loss 0.12569990 - samples/sec: 694.24\n",
      "2020-05-21 20:37:56,727 epoch 9 - iter 70/105 - loss 0.12143903 - samples/sec: 675.16\n",
      "2020-05-21 20:37:58,653 epoch 9 - iter 80/105 - loss 0.11832486 - samples/sec: 168.86\n",
      "2020-05-21 20:37:59,149 epoch 9 - iter 90/105 - loss 0.12000880 - samples/sec: 691.38\n",
      "2020-05-21 20:37:59,703 epoch 9 - iter 100/105 - loss 0.12083710 - samples/sec: 618.28\n",
      "2020-05-21 20:38:00,053 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:38:00,054 EPOCH 9 done: loss 0.1205 - lr 0.0500\n",
      "2020-05-21 20:38:02,043 DEV : loss 0.11633506417274475 - score 0.9578\n",
      "2020-05-21 20:38:02,592 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:38:06,139 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:38:07,060 epoch 10 - iter 10/105 - loss 0.06665972 - samples/sec: 558.93\n",
      "2020-05-21 20:38:07,659 epoch 10 - iter 20/105 - loss 0.08709721 - samples/sec: 576.04\n",
      "2020-05-21 20:38:08,209 epoch 10 - iter 30/105 - loss 0.11668457 - samples/sec: 633.91\n",
      "2020-05-21 20:38:08,787 epoch 10 - iter 40/105 - loss 0.11183876 - samples/sec: 599.57\n",
      "2020-05-21 20:38:09,367 epoch 10 - iter 50/105 - loss 0.10856042 - samples/sec: 588.73\n",
      "2020-05-21 20:38:09,894 epoch 10 - iter 60/105 - loss 0.11996933 - samples/sec: 666.04\n",
      "2020-05-21 20:38:10,450 epoch 10 - iter 70/105 - loss 0.11636873 - samples/sec: 624.60\n",
      "2020-05-21 20:38:10,950 epoch 10 - iter 80/105 - loss 0.11234126 - samples/sec: 684.31\n",
      "2020-05-21 20:38:11,461 epoch 10 - iter 90/105 - loss 0.11248726 - samples/sec: 673.57\n",
      "2020-05-21 20:38:11,925 epoch 10 - iter 100/105 - loss 0.11582617 - samples/sec: 707.41\n",
      "2020-05-21 20:38:12,281 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:38:12,282 EPOCH 10 done: loss 0.1142 - lr 0.0500\n",
      "2020-05-21 20:38:14,148 DEV : loss 0.11624106019735336 - score 0.9623\n",
      "2020-05-21 20:38:14,685 BAD EPOCHS (no improvement): 0\n",
      "2020-05-21 20:38:21,317 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-21 20:38:21,318 Testing using best model ...\n",
      "2020-05-21 20:38:21,319 loading file /notebooks/learning/spam_data/best-model.pt\n",
      "2020-05-21 20:38:25,646 0.9677\t0.9677\t0.9677\n",
      "2020-05-21 20:38:25,647 \n",
      "MICRO_AVG: acc 0.9374 - f1-score 0.9677\n",
      "MACRO_AVG: acc 0.8733 - f1-score 0.9299\n",
      "0          tp: 949 - fp: 24 - fn: 12 - tn: 130 - precision: 0.9753 - recall: 0.9875 - accuracy: 0.9635 - f1-score: 0.9814\n",
      "1          tp: 130 - fp: 12 - fn: 24 - tn: 949 - precision: 0.9155 - recall: 0.8442 - accuracy: 0.7831 - f1-score: 0.8784\n",
      "2020-05-21 20:38:25,648 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9677,\n",
       " 'dev_score_history': [0.8716,\n",
       "  0.8914,\n",
       "  0.9452,\n",
       "  0.9551,\n",
       "  0.9434,\n",
       "  0.9551,\n",
       "  0.9417,\n",
       "  0.9551,\n",
       "  0.9578,\n",
       "  0.9623],\n",
       " 'train_loss_history': [0.3271535288719904,\n",
       "  0.2627847296851022,\n",
       "  0.22043548237000193,\n",
       "  0.1896901235871372,\n",
       "  0.15060285879742533,\n",
       "  0.1360213768801519,\n",
       "  0.14464515138949666,\n",
       "  0.13471248827519872,\n",
       "  0.12050398377080758,\n",
       "  0.11418782712093421],\n",
       " 'dev_loss_history': [tensor(0.3075, device='cuda:0'),\n",
       "  tensor(0.2576, device='cuda:0'),\n",
       "  tensor(0.1767, device='cuda:0'),\n",
       "  tensor(0.1368, device='cuda:0'),\n",
       "  tensor(0.1774, device='cuda:0'),\n",
       "  tensor(0.1312, device='cuda:0'),\n",
       "  tensor(0.1518, device='cuda:0'),\n",
       "  tensor(0.1308, device='cuda:0'),\n",
       "  tensor(0.1163, device='cuda:0'),\n",
       "  tensor(0.1162, device='cuda:0')]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# start the training\n",
    "trainer.train(spampath, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:50:10,683 loading file /notebooks/learning/spam_data/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier.load(spampath/'best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 (0.9950962662696838)]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('Want to earn some money!?!')\n",
    "\n",
    "classifier.predict(sentence)\n",
    "\n",
    "print(sentence.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
